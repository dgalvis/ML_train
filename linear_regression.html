
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://dgalvis.github.io/ML_train/linear_regression.html">
      
      
        <link rel="prev" href="requirements.html">
      
      
        <link rel="next" href="logistic_regression.html">
      
      
      <link rel="icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>Linear Regression - Machine Learning Tutorials (ML_train)</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="green" data-md-color-accent="deep-purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#introduction" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="Machine Learning Tutorials (ML_train)" class="md-header__button md-logo" aria-label="Machine Learning Tutorials (ML_train)" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Machine Learning Tutorials (ML_train)
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Linear Regression
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/dgalvis/ML_train" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="Machine Learning Tutorials (ML_train)" class="md-nav__button md-logo" aria-label="Machine Learning Tutorials (ML_train)" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Machine Learning Tutorials (ML_train)
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/dgalvis/ML_train" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Machine Learning Tutorials
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="requirements.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Requirements
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Supervised Learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Supervised Learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Regression
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            Regression
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Linear Regression
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="linear_regression.html" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Linear Regression
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-definition" class="md-nav__link">
    <span class="md-ellipsis">
      Model Definition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fitting-the-model-ordinary-least-squares-ols" class="md-nav__link">
    <span class="md-ellipsis">
      Fitting the Model: Ordinary Least Squares (OLS)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#closed-form-solution" class="md-nav__link">
    <span class="md-ellipsis">
      Closed-Form Solution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-from-r" class="md-nav__link">
    <span class="md-ellipsis">
      Example from R
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-from-python" class="md-nav__link">
    <span class="md-ellipsis">
      Example from Python
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Example from Python">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#using-a-class-to-reproduce-the-r-statistics" class="md-nav__link">
    <span class="md-ellipsis">
      Using a class to reproduce the R statistics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-linearregression-class" class="md-nav__link">
    <span class="md-ellipsis">
      The LinearRegression class
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Classification
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Classification
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="logistic_regression.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Logistic Regression
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model-definition" class="md-nav__link">
    <span class="md-ellipsis">
      Model Definition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fitting-the-model-ordinary-least-squares-ols" class="md-nav__link">
    <span class="md-ellipsis">
      Fitting the Model: Ordinary Least Squares (OLS)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#closed-form-solution" class="md-nav__link">
    <span class="md-ellipsis">
      Closed-Form Solution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-from-r" class="md-nav__link">
    <span class="md-ellipsis">
      Example from R
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-from-python" class="md-nav__link">
    <span class="md-ellipsis">
      Example from Python
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Example from Python">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#using-a-class-to-reproduce-the-r-statistics" class="md-nav__link">
    <span class="md-ellipsis">
      Using a class to reproduce the R statistics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-linearregression-class" class="md-nav__link">
    <span class="md-ellipsis">
      The LinearRegression class
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>Linear Regression</h1>

<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>Linear regression is a type of supervised learning, where the goal is to identify a best-fit function between a dependent variable and one or more independent variables.</p>
<hr />
<h3 id="model-definition">Model Definition<a class="headerlink" href="#model-definition" title="Permanent link">&para;</a></h3>
<p>We assume the model takes the form:</p>
<div class="arithmatex">\[
y_i = \beta_0 + \beta_1 x_{i,1} + \dots + \beta_N x_{i,N} + \epsilon_i,
\]</div>
<p>where <span class="arithmatex">\( i = 1, \dots, M \)</span> indexes the samples in the training set.</p>
<p>The components of the model are:</p>
<ul>
<li><span class="arithmatex">\( x_{i,j} \)</span> — Feature <span class="arithmatex">\( j \)</span> for sample <span class="arithmatex">\( i \)</span>; there are <span class="arithmatex">\( N \)</span> features.</li>
<li><span class="arithmatex">\( y_i \)</span> — The output (target) for sample <span class="arithmatex">\( i \)</span>.</li>
<li><span class="arithmatex">\( \epsilon_i \)</span> — The error term, representing noise or unexplained variation.</li>
<li><span class="arithmatex">\( \beta_0 \)</span> — The intercept (bias).</li>
<li><span class="arithmatex">\( \beta_j \)</span> — The coefficient for feature <span class="arithmatex">\( j \)</span>.</li>
</ul>
<hr />
<h3 id="fitting-the-model-ordinary-least-squares-ols">Fitting the Model: Ordinary Least Squares (OLS)<a class="headerlink" href="#fitting-the-model-ordinary-least-squares-ols" title="Permanent link">&para;</a></h3>
<p>The most common way to fit a linear regression model is with the <strong>ordinary least squares (OLS)</strong> method. The objective is to find parameters <span class="arithmatex">\( \boldsymbol{\beta} \)</span> that minimise the following cost function:</p>
<div class="arithmatex">\[
J(\boldsymbol{\beta}) = \frac{1}{2} \sum_{i=1}^{M} \left(h_{\boldsymbol{\beta}}(X_i) - y_i\right)^2,
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\( \boldsymbol{\beta} = \begin{bmatrix} \beta_0 \\ \beta_1 \\ \vdots \\ \beta_N \end{bmatrix} \)</span> — Vector of model parameters.</li>
<li><span class="arithmatex">\( X_i = \begin{bmatrix} 1 &amp; x_{i,1} &amp; x_{i,2} &amp; \dots &amp; x_{i,N} \end{bmatrix} \)</span> — Row vector of features for sample <span class="arithmatex">\( i \)</span>, including a 1 to account for the bias term <span class="arithmatex">\( \beta_0 \)</span>.</li>
<li><span class="arithmatex">\( h_{\boldsymbol{\beta}}(X_i) \)</span> — The hypothesis (model) function, defined as:</li>
</ul>
<div class="arithmatex">\[
h_{\boldsymbol{\beta}}(X_i) = \beta_0 + \beta_1 x_{i,1} + \dots + \beta_N x_{i,N} = \boldsymbol{\beta}^\top X_i^\top.
\]</div>
<p>Thus, we are minimising the <strong>sum of squared differences</strong> between the predicted outputs <span class="arithmatex">\( h_{\boldsymbol{\beta}}(X_i) \)</span> and the actual outputs <span class="arithmatex">\( y_i \)</span> across all training samples.</p>
<hr />
<h3 id="closed-form-solution">Closed-Form Solution<a class="headerlink" href="#closed-form-solution" title="Permanent link">&para;</a></h3>
<p>To simplify notation and enable vectorised computation, we define:</p>
<ul>
<li>The <strong>design matrix</strong>:</li>
</ul>
<div class="arithmatex">\[
X = \begin{bmatrix}
X_1 \\
X_2 \\
\vdots \\
X_M
\end{bmatrix}
\quad \text{(an \( M \times (N+1) \) matrix)}
\]</div>
<ul>
<li>The output vector:</li>
</ul>
<div class="arithmatex">\[
\mathbf{y} = \begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_M
\end{bmatrix}
\]</div>
<p>OLS is one of the few machine learning methods with a <strong>closed-form analytic solution</strong> for the best-fit parameters. The solution is:</p>
<div class="arithmatex">\[
\boldsymbol{\beta} = (X^\top X)^{-1} X^\top \mathbf{y}
\]</div>
<p>This gives the value of <span class="arithmatex">\( \boldsymbol{\beta} \)</span> that minimises the cost function and fits the training data as closely as possible in the least-squares sense.</p>
<hr>
<hr>

<h2 id="example-from-r">Example from <code>R</code><a class="headerlink" href="#example-from-r" title="Permanent link">&para;</a></h2>
<p>The programming language <code>R</code> is widely used in statistics and data visualisation. It also provides a useful library of built-in datasets.</p>
<p>To explore this, navigate to the folder <code>./codes/</code> in the repository. Activate the virtual environment we created earlier (see <a href="requirements.html">Requirements</a>).</p>
<p>Then, launch Jupyter Notebook:</p>
<div class="language-bash highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">console</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1">1</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1"></a>jupyter<span class="w"> </span>notebook
</span></code></pre></div></td></tr></table></div>
<p>Open the notebook named <code>linear_regression_R.ipynb</code>, which contains <code>R</code> code. <strong>Make sure you use the <code>R</code> kernel.</strong> </p>
<p>We begin by importing <code>datasets</code> package:</p>
<div class="language-r highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">R</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-1-1">1</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="nf">library</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>This package includes several classic datasets, one of which is <code>USJudgeRatings</code>. This dataset contains average ratings for 43 judges across several dimensions (e.g., integrity, diligence, writing quality). The 12th column is the rating for “worthy of retention,” which we’ll try to predict using the first 11 features.</p>
<p>This command prints the first six rows of the dataset:</p>
<div class="language-r highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">R</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-2-1">1</a></span>
<span class="normal"><a href="#__codelineno-2-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="n">dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">USJudgeRatings</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2"></a><span class="nf">head</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<table class="dataframe">
<caption>US Judge Ratings</caption>
<thead>
    <tr><th></th><th scope=col>CONT</th><th scope=col>INTG</th><th scope=col>DMNR</th><th scope=col>DILG</th><th scope=col>CFMG</th><th scope=col>DECI</th><th scope=col>PREP</th><th scope=col>FAMI</th><th scope=col>ORAL</th><th scope=col>WRIT</th><th scope=col>PHYS</th><th scope=col>RTEN</th></tr>
</thead>
<tbody>
    <tr><th scope=row>AARONSON,L.H.</th><td>5.7</td><td>7.9</td><td>7.7</td><td>7.3</td><td>7.1</td><td>7.4</td><td>7.1</td><td>7.1</td><td>7.1</td><td>7.0</td><td>8.3</td><td>7.8</td></tr>
    <tr><th scope=row>ALEXANDER,J.M.</th><td>6.8</td><td>8.9</td><td>8.8</td><td>8.5</td><td>7.8</td><td>8.1</td><td>8.0</td><td>8.0</td><td>7.8</td><td>7.9</td><td>8.5</td><td>8.7</td></tr>
    <tr><th scope=row>ARMENTANO,A.J.</th><td>7.2</td><td>8.1</td><td>7.8</td><td>7.8</td><td>7.5</td><td>7.6</td><td>7.5</td><td>7.5</td><td>7.3</td><td>7.4</td><td>7.9</td><td>7.8</td></tr>
    <tr><th scope=row>BERDON,R.I.</th><td>6.8</td><td>8.8</td><td>8.5</td><td>8.8</td><td>8.3</td><td>8.5</td><td>8.7</td><td>8.7</td><td>8.4</td><td>8.5</td><td>8.8</td><td>8.7</td></tr>
    <tr><th scope=row>BRACKEN,J.J.</th><td>7.3</td><td>6.4</td><td>4.3</td><td>6.5</td><td>6.0</td><td>6.2</td><td>5.7</td><td>5.7</td><td>5.1</td><td>5.3</td><td>5.5</td><td>4.8</td></tr>
    <tr><th scope=row>BURNS,E.B.</th><td>6.2</td><td>8.8</td><td>8.7</td><td>8.5</td><td>7.9</td><td>8.0</td><td>8.1</td><td>8.0</td><td>8.0</td><td>8.0</td><td>8.6</td><td>8.6</td></tr>
</tbody>
</table>

<p>To prepare the data and run linear regression:</p>
<div class="language-r highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">R</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-3-1">1</a></span>
<span class="normal"><a href="#__codelineno-3-2">2</a></span>
<span class="normal"><a href="#__codelineno-3-3">3</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.matrix</span><span class="p">(</span><span class="n">dataset</span><span class="p">[,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">11</span><span class="p">)])</span><span class="w"> </span><span class="c1"># First 11 dimensions are Features</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2"></a><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.matrix</span><span class="p">(</span><span class="n">dataset</span><span class="p">[,</span><span class="w"> </span><span class="m">12</span><span class="p">])</span><span class="w"> </span><span class="c1"># last dimeions is the Output (Retention rating)</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3"></a><span class="n">reg</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>This creates matrices <code>x</code> and <code>y</code> and uses the <code>lm</code> function to perform linear regression.</p>
<p>To see the model summary:</p>
<div class="language-r highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">R</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-4-1">1</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="nf">summary</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>This produces several useful statistics:
<div class="language-text highlight"><span class="filename">Output</span><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>Call:
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>lm(formula = y ~ x)
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>Residuals:
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>     Min       1Q   Median       3Q      Max
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>-0.22123 -0.06155 -0.01055  0.05045  0.26079
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>Coefficients:
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>            Estimate Std. Error t value Pr(&gt;|t|)
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>(Intercept) -2.11943    0.51904  -4.083 0.000290 ***
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>xCONT        0.01280    0.02586   0.495 0.624272
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>xINTG        0.36484    0.12936   2.820 0.008291 **
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>xDMNR        0.12540    0.08971   1.398 0.172102
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a>xDILG        0.06669    0.14303   0.466 0.644293
</span><span id="__span-5-15"><a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a>xCFMG       -0.19453    0.14779  -1.316 0.197735
</span><span id="__span-5-16"><a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a>xDECI        0.27829    0.13826   2.013 0.052883 .
</span><span id="__span-5-17"><a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a>xPREP       -0.00196    0.24001  -0.008 0.993536
</span><span id="__span-5-18"><a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a>xFAMI       -0.13579    0.26725  -0.508 0.614972
</span><span id="__span-5-19"><a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a>xORAL        0.54782    0.27725   1.976 0.057121 .
</span><span id="__span-5-20"><a id="__codelineno-5-20" name="__codelineno-5-20" href="#__codelineno-5-20"></a>xWRIT       -0.06806    0.31485  -0.216 0.830269
</span><span id="__span-5-21"><a id="__codelineno-5-21" name="__codelineno-5-21" href="#__codelineno-5-21"></a>xPHYS        0.26881    0.06213   4.326 0.000146 ***
</span><span id="__span-5-22"><a id="__codelineno-5-22" name="__codelineno-5-22" href="#__codelineno-5-22"></a>---
</span><span id="__span-5-23"><a id="__codelineno-5-23" name="__codelineno-5-23" href="#__codelineno-5-23"></a>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</span><span id="__span-5-24"><a id="__codelineno-5-24" name="__codelineno-5-24" href="#__codelineno-5-24"></a>
</span><span id="__span-5-25"><a id="__codelineno-5-25" name="__codelineno-5-25" href="#__codelineno-5-25"></a>Residual standard error: 0.1174 on 31 degrees of freedom
</span><span id="__span-5-26"><a id="__codelineno-5-26" name="__codelineno-5-26" href="#__codelineno-5-26"></a>Multiple R-squared:  0.9916,    Adjusted R-squared:  0.9886
</span><span id="__span-5-27"><a id="__codelineno-5-27" name="__codelineno-5-27" href="#__codelineno-5-27"></a>F-statistic: 332.9 on 11 and 31 DF,  p-value: &lt; 2.2e-16
</span></code></pre></div></p>
<p>I don't know about you, but I think this is <strong>mega</strong>. However, we’ll take it a step further and write our own <code>Python</code> code — mostly from scratch — to calculate these statistics ourselves and better understand what they mean.</p>
<hr>
<hr>

<h2 id="example-from-python">Example from Python<a class="headerlink" href="#example-from-python" title="Permanent link">&para;</a></h2>
<h3 id="using-a-class-to-reproduce-the-r-statistics">Using a class to reproduce the <code>R</code> statistics<a class="headerlink" href="#using-a-class-to-reproduce-the-r-statistics" title="Permanent link">&para;</a></h3>
<p>In this example, we will implement a <code>LinearRegression</code> class in Python that performs linear regression and reproduces the same statistics that the <code>R</code> <code>summary</code> function outputs.</p>
<p>To explore this example, navigate to the folder <code>./codes/</code> in the repository.
Activate the virtual environment we created earlier (see <a href="requirements.html">Requirements</a>).</p>
<p>Launch Jupyter Notebook:</p>
<div class="language-bash highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">console</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-6-1">1</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1"></a>jupyter<span class="w"> </span>notebook
</span></code></pre></div></td></tr></table></div>
<p>Open the notebook named <code>linear_regression_py.ipynb</code>, which contains <code>Python</code> code. <strong>Make sure you use the <code>Python 3</code> kernel.</strong> </p>
<p>We start by importing <code>pandas</code> for data handling and the <code>LinearRegression</code> class from our module:</p>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-7-1">1</a></span>
<span class="normal"><a href="#__codelineno-7-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">modules.lin_reg</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span> 
</span></code></pre></div></td></tr></table></div>
<p>The <code>pandas</code> library makes it easy to load tabular datasets, such as the <code>USJudgeRatings</code> data stored in a CSV file:</p>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-8-1">1</a></span>
<span class="normal"><a href="#__codelineno-8-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1"></a><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/USJudgeRatings.csv&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</span></code></pre></div></td></tr></table></div>
<p>To prepare the data, we convert the <code>DataFrame</code> to NumPy arrays:</p>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-9-1">1</a></span>
<span class="normal"><a href="#__codelineno-9-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1"></a><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2"></a><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></code></pre></div></td></tr></table></div>
<p>Then, we create the <code>LinearRegression</code> instance and fit the data:</p>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-10-1">1</a></span>
<span class="normal"><a href="#__codelineno-10-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1"></a><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2"></a><span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<p>To display the regression results, call the <code>summary()</code> method::</p>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-11-1">1</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1"></a><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
<p>This produces the same statistics as the <code>R</code> summary:</p>
<div class="language-text highlight"><span class="filename">Output</span><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>Residuals:
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>Min: -0.2212
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>Q1:  -0.0615
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>Med: -0.0105
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>Q3:  0.0505
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>Max: 0.2608
</span><span id="__span-12-7"><a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>
</span><span id="__span-12-8"><a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a> Coefficient   Std Error     t-value     p-value
</span><span id="__span-12-9"><a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a>     -2.1194      0.5190     -4.0834   0.0002896
</span><span id="__span-12-10"><a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>      0.0128      0.0259      0.4947      0.6243
</span><span id="__span-12-11"><a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a>      0.3648      0.1294      2.8204    0.008291
</span><span id="__span-12-12"><a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a>      0.1254      0.0897      1.3978      0.1721
</span><span id="__span-12-13"><a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>      0.0667      0.1430      0.4663      0.6443
</span><span id="__span-12-14"><a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>     -0.1945      0.1478     -1.3163      0.1977
</span><span id="__span-12-15"><a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a>      0.2783      0.1383      2.0129     0.05288
</span><span id="__span-12-16"><a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a>     -0.0020      0.2400     -0.0082      0.9935
</span><span id="__span-12-17"><a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a>     -0.1358      0.2672     -0.5081       0.615
</span><span id="__span-12-18"><a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a>      0.5478      0.2772      1.9759     0.05712
</span><span id="__span-12-19"><a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a>     -0.0681      0.3148     -0.2162      0.8303
</span><span id="__span-12-20"><a id="__codelineno-12-20" name="__codelineno-12-20" href="#__codelineno-12-20"></a>      0.2688      0.0621      4.3263   0.0001464
</span><span id="__span-12-21"><a id="__codelineno-12-21" name="__codelineno-12-21" href="#__codelineno-12-21"></a>
</span><span id="__span-12-22"><a id="__codelineno-12-22" name="__codelineno-12-22" href="#__codelineno-12-22"></a>Residual standard error: 0.1174
</span><span id="__span-12-23"><a id="__codelineno-12-23" name="__codelineno-12-23" href="#__codelineno-12-23"></a>R-squared:             0.9916
</span><span id="__span-12-24"><a id="__codelineno-12-24" name="__codelineno-12-24" href="#__codelineno-12-24"></a>Adjusted R-squared:    0.9886
</span><span id="__span-12-25"><a id="__codelineno-12-25" name="__codelineno-12-25" href="#__codelineno-12-25"></a>F-statistic:           332.8597
</span><span id="__span-12-26"><a id="__codelineno-12-26" name="__codelineno-12-26" href="#__codelineno-12-26"></a>F-statistic p-value:   1.11e-16
</span></code></pre></div>
<p>Next, we will unpack the <code>LinearRegression</code> class to see how it works!</p>
<hr>

<h3 id="the-linearregression-class">The <code>LinearRegression</code> class<a class="headerlink" href="#the-linearregression-class" title="Permanent link">&para;</a></h3>
<p>All Python source code for this example is stored in the folder <code>./codes/modules/</code>.</p>
<ul>
<li>The file <code>__init__.py</code> marks the directory as a <strong>Python package</strong>, allowing you to import its modules elsewhere in your project.</li>
<li>The file <code>lin_reg.py</code> defines the <code>LinearRegression</code> <strong>class</strong>, which implements our regression model and associated methods.</li>
<li>The file <code>test_lin_reg.py</code> contains <strong>unit tests</strong> to verify that the implementation in <code>lin_reg.py</code> works correctly<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup>.</li>
</ul>
<p>We start by importing the required libraries:</p>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-13-1">1</a></span>
<span class="normal"><a href="#__codelineno-13-2">2</a></span>
<span class="normal"><a href="#__codelineno-13-3">3</a></span>
<span class="normal"><a href="#__codelineno-13-4">4</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tuple</span>
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">numpy.typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">NDArray</span>
</span></code></pre></div></td></tr></table></div>
<p>Every <code>Python</code> class can define an <strong>initialiser method</strong> (often called the <em>constructor</em> in other languages) using <code>__init__</code>.
This special method is automatically executed when a new instance of the class is created<sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup>.</p>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-14-1">1</a></span>
<span class="normal"><a href="#__codelineno-14-2">2</a></span>
<span class="normal"><a href="#__codelineno-14-3">3</a></span>
<span class="normal"><a href="#__codelineno-14-4">4</a></span>
<span class="normal"><a href="#__codelineno-14-5">5</a></span>
<span class="normal"><a href="#__codelineno-14-6">6</a></span>
<span class="normal"><a href="#__codelineno-14-7">7</a></span>
<span class="normal"><a href="#__codelineno-14-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">LinearRegression</span><span class="p">:</span>
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Ordinary Least Squares (OLS) linear regression using the normal equation.&quot;&quot;&quot;</span>
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3"></a>
</span><span id="__span-14-4"><a id="__codelineno-14-4" name="__codelineno-14-4"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">add_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="__span-14-5"><a id="__codelineno-14-5" name="__codelineno-14-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_add_bias</span> <span class="o">=</span> <span class="n">add_bias</span> <span class="c1"># Whether to include an intercept β₀</span>
</span><span id="__span-14-6"><a id="__codelineno-14-6" name="__codelineno-14-6"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># Will hold fitted coefficients </span>
</span><span id="__span-14-7"><a id="__codelineno-14-7" name="__codelineno-14-7"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># Stores training features (with bias if added) </span>
</span><span id="__span-14-8"><a id="__codelineno-14-8" name="__codelineno-14-8"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># Stores training target values</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="fitting-the-model">Fitting the model<a class="headerlink" href="#fitting-the-model" title="Permanent link">&para;</a></h4>
<p>The <code>fit</code> method computes the OLS solution:</p>
<ul>
<li>Adds a column of ones to <code>X</code> if an intercept term is included.</li>
<li>Computes the regression coefficients using the pseudoinverse of <span class="arithmatex">\(X^T X\)</span>.</li>
<li>Stores <code>X</code>, <code>y</code> and the fitted coefficients in the instance for later use.</li>
</ul>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-15-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-15-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-15-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-15-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-15-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-15-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-15-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-15-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-15-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-15-10">10</a></span>
<span class="normal"><a href="#__codelineno-15-11">11</a></span>
<span class="normal"><a href="#__codelineno-15-12">12</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="n">y</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_bias</span><span class="p">:</span>
</span><span id="__span-15-3"><a id="__codelineno-15-3" name="__codelineno-15-3"></a>        <span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="__span-15-4"><a id="__codelineno-15-4" name="__codelineno-15-4"></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span>
</span><span id="__span-15-5"><a id="__codelineno-15-5" name="__codelineno-15-5"></a>
</span><span id="__span-15-6"><a id="__codelineno-15-6" name="__codelineno-15-6"></a>    <span class="n">XtX_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span>
</span><span id="__span-15-7"><a id="__codelineno-15-7" name="__codelineno-15-7"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">XtX_inv</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>
</span><span id="__span-15-8"><a id="__codelineno-15-8" name="__codelineno-15-8"></a>
</span><span id="__span-15-9"><a id="__codelineno-15-9" name="__codelineno-15-9"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
</span><span id="__span-15-10"><a id="__codelineno-15-10" name="__codelineno-15-10"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
</span><span id="__span-15-11"><a id="__codelineno-15-11" name="__codelineno-15-11"></a>
</span><span id="__span-15-12"><a id="__codelineno-15-12" name="__codelineno-15-12"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="making-predictions-train-vs-test">Making predictions (train vs. test)<a class="headerlink" href="#making-predictions-train-vs-test" title="Permanent link">&para;</a></h4>
<p>The <strong>learned relationship</strong> lives entirely in the fitted coefficients <span class="arithmatex">\( \boldsymbol{\beta} \)</span> that are computed during <code>fit(X_train, y_train)</code>.<br />
Once <code>beta</code> is set, you can call <code>predict(X)</code> on <strong>any</strong> dataset that has the same feature schema:</p>
<ul>
<li><strong>Training predictions:</strong> <code>predict(X_train)</code></li>
<li><strong>Test/Validation predictions:</strong> <code>predict(X_test)</code></li>
</ul>
<p>Mathematically, predictions are always
$$
\hat{\mathbf{y}} = X\,\boldsymbol{\beta}.
$$</p>
<p>If the model was created with <code>add_bias=True</code>, <code>predict</code> will <strong>automatically prepend</strong> the column of ones to whatever <code>X</code> you pass in. It then delegates to the internal <code>_predict</code>, which assumes <code>X</code> is already in final matrix form (bias included if needed).</p>
<blockquote>
<p>Note: Do not re-fit on test data. Fit once on training data, then reuse the same beta to evaluate on validation/test sets (using <code>predict</code>).</p>
</blockquote>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-16-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-16-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-16-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-16-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-16-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-16-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-16-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-16-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-16-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-16-10">10</a></span>
<span class="normal"><a href="#__codelineno-16-11">11</a></span>
<span class="normal"><a href="#__codelineno-16-12">12</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
</span><span id="__span-16-2"><a id="__codelineno-16-2" name="__codelineno-16-2"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-16-3"><a id="__codelineno-16-3" name="__codelineno-16-3"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model has not been fitted yet.&quot;</span><span class="p">)</span>
</span><span id="__span-16-4"><a id="__codelineno-16-4" name="__codelineno-16-4"></a>
</span><span id="__span-16-5"><a id="__codelineno-16-5" name="__codelineno-16-5"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_bias</span><span class="p">:</span>
</span><span id="__span-16-6"><a id="__codelineno-16-6" name="__codelineno-16-6"></a>        <span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="__span-16-7"><a id="__codelineno-16-7" name="__codelineno-16-7"></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span>
</span><span id="__span-16-8"><a id="__codelineno-16-8" name="__codelineno-16-8"></a>
</span><span id="__span-16-9"><a id="__codelineno-16-9" name="__codelineno-16-9"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="__span-16-10"><a id="__codelineno-16-10" name="__codelineno-16-10"></a>
</span><span id="__span-16-11"><a id="__codelineno-16-11" name="__codelineno-16-11"></a><span class="k">def</span><span class="w"> </span><span class="nf">_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
</span><span id="__span-16-12"><a id="__codelineno-16-12" name="__codelineno-16-12"></a>    <span class="k">return</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="computing-residuals-train-vs-test">Computing residuals (train vs. test)<a class="headerlink" href="#computing-residuals-train-vs-test" title="Permanent link">&para;</a></h4>
<p>Residuals are the differences between observed targets and predictions:
$$
\mathbf{r} = \mathbf{y} - \hat{\mathbf{y}} = \mathbf{y} - X\boldsymbol{\beta}
$$</p>
<p>Use the same <code>residuals(X, y)</code> method for either training or test data:</p>
<ul>
<li><strong>Training residuals</strong>: <code>residuals(X_train, y_train)</code></li>
<li><strong>Test/validation residuals</strong>:<code>residuals(X_test, y_test)</code></li>
</ul>
<p>As with <code>predict</code>, if <code>add_bias=True</code>, the public <code>residuals</code> method will <strong>add the bias column for you</strong> before delegating to <code>_residuals</code>. The private <code>_residuals</code> assumes X is already prepared.</p>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-17-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-17-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-17-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-17-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-17-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-17-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-17-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-17-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-17-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-17-10">10</a></span>
<span class="normal"><a href="#__codelineno-17-11">11</a></span>
<span class="normal"><a href="#__codelineno-17-12">12</a></span>
<span class="normal"><a href="#__codelineno-17-13">13</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">residuals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="n">y</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
</span><span id="__span-17-2"><a id="__codelineno-17-2" name="__codelineno-17-2"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-17-3"><a id="__codelineno-17-3" name="__codelineno-17-3"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model has not been fitted yet.&quot;</span><span class="p">)</span>
</span><span id="__span-17-4"><a id="__codelineno-17-4" name="__codelineno-17-4"></a>
</span><span id="__span-17-5"><a id="__codelineno-17-5" name="__codelineno-17-5"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_bias</span><span class="p">:</span>
</span><span id="__span-17-6"><a id="__codelineno-17-6" name="__codelineno-17-6"></a>        <span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="__span-17-7"><a id="__codelineno-17-7" name="__codelineno-17-7"></a>        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span>
</span><span id="__span-17-8"><a id="__codelineno-17-8" name="__codelineno-17-8"></a>
</span><span id="__span-17-9"><a id="__codelineno-17-9" name="__codelineno-17-9"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_residuals</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="__span-17-10"><a id="__codelineno-17-10" name="__codelineno-17-10"></a>
</span><span id="__span-17-11"><a id="__codelineno-17-11" name="__codelineno-17-11"></a><span class="k">def</span><span class="w"> </span><span class="nf">_residuals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="n">y</span><span class="p">:</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
</span><span id="__span-17-12"><a id="__codelineno-17-12" name="__codelineno-17-12"></a>    <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="__span-17-13"><a id="__codelineno-17-13" name="__codelineno-17-13"></a>    <span class="k">return</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span>
</span></code></pre></div></td></tr></table></div>
<h4 id="calculating-statistics">Calculating Statistics<a class="headerlink" href="#calculating-statistics" title="Permanent link">&para;</a></h4>
<h5 id="residual-summary-statistics">Residual summary statistics<a class="headerlink" href="#residual-summary-statistics" title="Permanent link">&para;</a></h5>
<p>The <code>residual_stats</code> method returns the <strong>five-number summary</strong> of the model residuals:</p>
<ul>
<li><strong>Minimum</strong>: the smallest residual value.</li>
<li><strong>Q1 (25th percentile)</strong>: the value below which 25% of residuals lie.</li>
<li><strong>Median</strong>: the middle value (50th percentile) of the residuals.</li>
<li><strong>Q3 (75th percentile)</strong>: the value below which 75% of residuals lie.</li>
<li><strong>Maximum</strong>: the largest residual value.</li>
</ul>
<p>These statistics are useful for identifying skewness or outliers in the residual distribution.
They mirror the residual summary output seen in statistical software like R.</p>
<p>Mathematically, if <span class="arithmatex">\(\mathbf{r} = \mathbf{y} - \hat{\mathbf{y}}\)</span>, then:</p>
<div class="arithmatex">\[
\text{summary}(\mathbf{r}) =
\big[
\min(\mathbf{r}),
Q_1(\mathbf{r}),
\operatorname{median}(\mathbf{r}),
Q_3(\mathbf{r}),
\max(\mathbf{r})
\big]
\]</div>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-18-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-18-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-18-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-18-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-18-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-18-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-18-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-18-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-18-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-18-10">10</a></span>
<span class="normal"><a href="#__codelineno-18-11">11</a></span>
<span class="normal"><a href="#__codelineno-18-12">12</a></span>
<span class="normal"><a href="#__codelineno-18-13">13</a></span>
<span class="normal"><a href="#__codelineno-18-14">14</a></span>
<span class="normal"><a href="#__codelineno-18-15">15</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">residual_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-18-3"><a id="__codelineno-18-3" name="__codelineno-18-3"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model has not been fitted yet.&quot;</span><span class="p">)</span>
</span><span id="__span-18-4"><a id="__codelineno-18-4" name="__codelineno-18-4"></a>
</span><span id="__span-18-5"><a id="__codelineno-18-5" name="__codelineno-18-5"></a>    <span class="c1"># Compute residuals using stored training data</span>
</span><span id="__span-18-6"><a id="__codelineno-18-6" name="__codelineno-18-6"></a>    <span class="n">residuals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_residuals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
</span><span id="__span-18-7"><a id="__codelineno-18-7" name="__codelineno-18-7"></a>
</span><span id="__span-18-8"><a id="__codelineno-18-8" name="__codelineno-18-8"></a>    <span class="c1"># Compute and return five-number summary as a NumPy array</span>
</span><span id="__span-18-9"><a id="__codelineno-18-9" name="__codelineno-18-9"></a>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
</span><span id="__span-18-10"><a id="__codelineno-18-10" name="__codelineno-18-10"></a>        <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">residuals</span><span class="p">),</span>
</span><span id="__span-18-11"><a id="__codelineno-18-11" name="__codelineno-18-11"></a>        <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span>
</span><span id="__span-18-12"><a id="__codelineno-18-12" name="__codelineno-18-12"></a>        <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">residuals</span><span class="p">),</span>
</span><span id="__span-18-13"><a id="__codelineno-18-13" name="__codelineno-18-13"></a>        <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="mi">75</span><span class="p">),</span>
</span><span id="__span-18-14"><a id="__codelineno-18-14" name="__codelineno-18-14"></a>        <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span>
</span><span id="__span-18-15"><a id="__codelineno-18-15" name="__codelineno-18-15"></a>    <span class="p">])</span>
</span></code></pre></div></td></tr></table></div>
<h5 id="residual-standard-error-rse">Residual Standard Error (RSE)<a class="headerlink" href="#residual-standard-error-rse" title="Permanent link">&para;</a></h5>
<p>The <strong>Residual Standard Error</strong> (RSE) measures the typical size of the residuals — in other words, how far the model's predictions are from the observed values on average.</p>
<p>It is defined as:
$$
\mathrm{RSE} = \sqrt{\frac{\mathrm{RSS}}{n - p}}
$$</p>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(\mathrm{RSS} = \sum_{i=1}^n r_i^2\)</span> is the <strong>Residual Sum of Squares</strong>,</li>
<li><span class="arithmatex">\(n\)</span> is the number of observations,</li>
<li><span class="arithmatex">\(p\)</span> is the number of estimated parameters (including the intercept).</li>
</ul>
<p>This formula is equivalent to taking the square root of the estimated error variance:
$$
\hat{\sigma}^2 = \frac{\mathrm{RSS}}{n - p}
\quad\Rightarrow\quad
\mathrm{RSE} = \sqrt{\hat{\sigma}^2}
$$</p>
<p>The RSE is expressed in the same units as the dependent variable, making it easy to interpret: a smaller RSE means the model predictions are closer to the observed values.</p>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-19-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-19-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-19-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-19-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-19-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-19-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-19-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-19-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-19-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-19-10">10</a></span>
<span class="normal"><a href="#__codelineno-19-11">11</a></span>
<span class="normal"><a href="#__codelineno-19-12">12</a></span>
<span class="normal"><a href="#__codelineno-19-13">13</a></span>
<span class="normal"><a href="#__codelineno-19-14">14</a></span>
<span class="normal"><a href="#__codelineno-19-15">15</a></span>
<span class="normal"><a href="#__codelineno-19-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">residuals_SE</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="__span-19-2"><a id="__codelineno-19-2" name="__codelineno-19-2"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-19-3"><a id="__codelineno-19-3" name="__codelineno-19-3"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model has not been fitted yet.&quot;</span><span class="p">)</span>
</span><span id="__span-19-4"><a id="__codelineno-19-4" name="__codelineno-19-4"></a>
</span><span id="__span-19-5"><a id="__codelineno-19-5" name="__codelineno-19-5"></a>    <span class="c1"># Compute residuals using stored data</span>
</span><span id="__span-19-6"><a id="__codelineno-19-6" name="__codelineno-19-6"></a>    <span class="n">residuals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_residuals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
</span><span id="__span-19-7"><a id="__codelineno-19-7" name="__codelineno-19-7"></a>
</span><span id="__span-19-8"><a id="__codelineno-19-8" name="__codelineno-19-8"></a>    <span class="c1"># Number of observations and parameters</span>
</span><span id="__span-19-9"><a id="__codelineno-19-9" name="__codelineno-19-9"></a>    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span>
</span><span id="__span-19-10"><a id="__codelineno-19-10" name="__codelineno-19-10"></a>    <span class="n">p</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="__span-19-11"><a id="__codelineno-19-11" name="__codelineno-19-11"></a>
</span><span id="__span-19-12"><a id="__codelineno-19-12" name="__codelineno-19-12"></a>    <span class="c1"># Compute residual sum of squares and standard error</span>
</span><span id="__span-19-13"><a id="__codelineno-19-13" name="__codelineno-19-13"></a>    <span class="n">RSS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">residuals</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="__span-19-14"><a id="__codelineno-19-14" name="__codelineno-19-14"></a>    <span class="n">RSE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">RSS</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">p</span><span class="p">))</span>
</span><span id="__span-19-15"><a id="__codelineno-19-15" name="__codelineno-19-15"></a>
</span><span id="__span-19-16"><a id="__codelineno-19-16" name="__codelineno-19-16"></a>    <span class="k">return</span> <span class="n">RSE</span>
</span></code></pre></div></td></tr></table></div>
<h5 id="coefficient-of-determination-r2-and-adjusted-r2">Coefficient of Determination: <span class="arithmatex">\(R^2\)</span> and adjusted <span class="arithmatex">\(R^2\)</span><a class="headerlink" href="#coefficient-of-determination-r2-and-adjusted-r2" title="Permanent link">&para;</a></h5>
<p>The <strong>coefficient of determination</strong> <span class="arithmatex">\(R^2\)</span> measures the proportion of variability in the dependent variable that is explained by the model:</p>
<div class="arithmatex">\[
R^2 = 1 - \frac{\mathrm{RSS}}{\mathrm{TSS}}
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(\mathrm{RSS} = \sum_{i=1}^n r_i^2\)</span> is the <strong>Residual Sum of Squares</strong> (unexplained variance),</li>
<li><span class="arithmatex">\(\mathrm{TSS} = \sum_{i=1}^n (y_i - \bar{y})^2\)</span> is the <strong>Total Sum of Squares</strong> (total variance in the data).</li>
</ul>
<p>While <span class="arithmatex">\(R^2\)</span> indicates goodness of fit, it always increases when more predictors are added — even if they are not useful.<br />
To account for this, we compute the <strong>adjusted <span class="arithmatex">\(R^2\)</span></strong>:</p>
<div class="arithmatex">\[
R^2_{\text{adj}} = 1 - \frac{\mathrm{RSS}/(n - p)}{\mathrm{TSS}/(n - 1)}
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(n\)</span> = number of observations,</li>
<li><span class="arithmatex">\(p\)</span> = number of estimated parameters (including the intercept).</li>
</ul>
<p>Adjusted <span class="arithmatex">\(R^2\)</span> penalizes the inclusion of unnecessary predictors, making it a better measure for comparing models with different numbers of features.</p>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-20-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-20-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-20-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-20-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-20-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-20-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-20-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-20-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-20-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-20-10">10</a></span>
<span class="normal"><a href="#__codelineno-20-11">11</a></span>
<span class="normal"><a href="#__codelineno-20-12">12</a></span>
<span class="normal"><a href="#__codelineno-20-13">13</a></span>
<span class="normal"><a href="#__codelineno-20-14">14</a></span>
<span class="normal"><a href="#__codelineno-20-15">15</a></span>
<span class="normal"><a href="#__codelineno-20-16">16</a></span>
<span class="normal"><a href="#__codelineno-20-17">17</a></span>
<span class="normal"><a href="#__codelineno-20-18">18</a></span>
<span class="normal"><a href="#__codelineno-20-19">19</a></span>
<span class="normal"><a href="#__codelineno-20-20">20</a></span>
<span class="normal"><a href="#__codelineno-20-21">21</a></span>
<span class="normal"><a href="#__codelineno-20-22">22</a></span>
<span class="normal"><a href="#__codelineno-20-23">23</a></span>
<span class="normal"><a href="#__codelineno-20-24">24</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">R_squared</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-20-2"><a id="__codelineno-20-2" name="__codelineno-20-2"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-20-3"><a id="__codelineno-20-3" name="__codelineno-20-3"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model has not been fitted yet.&quot;</span><span class="p">)</span>
</span><span id="__span-20-4"><a id="__codelineno-20-4" name="__codelineno-20-4"></a>
</span><span id="__span-20-5"><a id="__codelineno-20-5" name="__codelineno-20-5"></a>    <span class="c1"># Compute residuals using stored training data</span>
</span><span id="__span-20-6"><a id="__codelineno-20-6" name="__codelineno-20-6"></a>    <span class="n">residuals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_residuals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
</span><span id="__span-20-7"><a id="__codelineno-20-7" name="__codelineno-20-7"></a>
</span><span id="__span-20-8"><a id="__codelineno-20-8" name="__codelineno-20-8"></a>    <span class="c1"># Number of observations and estimated parameters</span>
</span><span id="__span-20-9"><a id="__codelineno-20-9" name="__codelineno-20-9"></a>    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span>
</span><span id="__span-20-10"><a id="__codelineno-20-10" name="__codelineno-20-10"></a>    <span class="n">p</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="__span-20-11"><a id="__codelineno-20-11" name="__codelineno-20-11"></a>
</span><span id="__span-20-12"><a id="__codelineno-20-12" name="__codelineno-20-12"></a>    <span class="c1"># Residual Sum of Squares (unexplained variance)</span>
</span><span id="__span-20-13"><a id="__codelineno-20-13" name="__codelineno-20-13"></a>    <span class="n">RSS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">residuals</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="__span-20-14"><a id="__codelineno-20-14" name="__codelineno-20-14"></a>
</span><span id="__span-20-15"><a id="__codelineno-20-15" name="__codelineno-20-15"></a>    <span class="c1"># Total Sum of Squares (total variance in y)</span>
</span><span id="__span-20-16"><a id="__codelineno-20-16" name="__codelineno-20-16"></a>    <span class="n">TSS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="__span-20-17"><a id="__codelineno-20-17" name="__codelineno-20-17"></a>
</span><span id="__span-20-18"><a id="__codelineno-20-18" name="__codelineno-20-18"></a>    <span class="c1"># R² = 1 - RSS/TSS</span>
</span><span id="__span-20-19"><a id="__codelineno-20-19" name="__codelineno-20-19"></a>    <span class="n">R_squared</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">RSS</span> <span class="o">/</span> <span class="n">TSS</span>
</span><span id="__span-20-20"><a id="__codelineno-20-20" name="__codelineno-20-20"></a>
</span><span id="__span-20-21"><a id="__codelineno-20-21" name="__codelineno-20-21"></a>    <span class="c1"># Adjusted R² penalizes for model complexity</span>
</span><span id="__span-20-22"><a id="__codelineno-20-22" name="__codelineno-20-22"></a>    <span class="n">R_squared_adj</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">RSS</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">p</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">TSS</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="__span-20-23"><a id="__codelineno-20-23" name="__codelineno-20-23"></a>
</span><span id="__span-20-24"><a id="__codelineno-20-24" name="__codelineno-20-24"></a>    <span class="k">return</span> <span class="n">R_squared</span><span class="p">,</span> <span class="n">R_squared_adj</span>
</span></code></pre></div></td></tr></table></div>
<h5 id="overall-significance-the-f-stat-and-p-value">Overall significance: the F-stat and p-value<a class="headerlink" href="#overall-significance-the-f-stat-and-p-value" title="Permanent link">&para;</a></h5>
<p>The <strong><span class="arithmatex">\(F\)</span>-statistic</strong> tests the null hypothesis that <strong>all regression coefficients except the intercept are equal to zero</strong>:</p>
<div class="arithmatex">\[
H_0: \beta_1 = \beta_2 = \dots = \beta_{p-1} = 0
\]</div>
<p>In other words, it checks whether the model provides a better fit than one with only the intercept.</p>
<ul>
<li>
<p><strong>Calculate MSR and MSE</strong>: Let <span class="arithmatex">\(\mathrm{TSS}\)</span> be the <strong>Total Sum of Squares</strong> and <span class="arithmatex">\(\mathrm{RSS}\)</span> be the <strong>Residual Sum of Squares</strong>:</p>
<ul>
<li><strong>Mean Square Regression (MSR)</strong> — average explained variance per parameter:
  $$
  \mathrm{MSR} = \frac{\mathrm{TSS} - \mathrm{RSS}}{df_1}
  $$
  where:<ul>
<li><span class="arithmatex">\(df_1 = p - 1\)</span> (if <code>self._add_bias=True</code>) </li>
<li><span class="arithmatex">\(df_1 = p\)</span> (if <code>self._add_bias = False</code>).</li>
</ul>
</li>
<li><strong>Mean Square Error (MSE)</strong> — average unexplained variance per residual degree of freedom:
  $$
  \mathrm{MSE} = \frac{\mathrm{RSS}}{df_2}
  $$
  where <span class="arithmatex">\(df_2 = n-p\)</span>.</li>
</ul>
</li>
<li>
<p><strong>Calculate  <span class="arithmatex">\(F\)</span>-statistic and p-value</strong>: 
    The <span class="arithmatex">\(F\)</span>-statistic is the ratio:
    $$
    F = \frac{\mathrm{MSR}}{\mathrm{MSE}}
    $$</p>
<p>A large <span class="arithmatex">\(F\)</span>-value suggests that the model explains significantly more variance than would be expected by chance.
The <strong>p-value</strong> is computed from the right tail of the <span class="arithmatex">\(F\)</span>-distribution with <span class="arithmatex">\((df_1, df_2)\)</span> degrees of freedom.
The one-tailed p-value is:
$$
p = \left( 1 - \text{CDF}_{df_1, df_2}(F)\right).
$$</p>
</li>
<li>
<p><strong>Interpretation</strong>:</p>
<ul>
<li>Small p-value (reject <span class="arithmatex">\(H_0\)</span>): at least one predictor is significantly associated with the response.</li>
<li>Large p-value (fail to reject <span class="arithmatex">\(H_0\)</span>): no evidence the predictors improve the model.</li>
</ul>
</li>
</ul>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-21-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-21-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-21-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-21-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-21-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-21-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-21-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-21-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-21-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-21-10">10</a></span>
<span class="normal"><a href="#__codelineno-21-11">11</a></span>
<span class="normal"><a href="#__codelineno-21-12">12</a></span>
<span class="normal"><a href="#__codelineno-21-13">13</a></span>
<span class="normal"><a href="#__codelineno-21-14">14</a></span>
<span class="normal"><a href="#__codelineno-21-15">15</a></span>
<span class="normal"><a href="#__codelineno-21-16">16</a></span>
<span class="normal"><a href="#__codelineno-21-17">17</a></span>
<span class="normal"><a href="#__codelineno-21-18">18</a></span>
<span class="normal"><a href="#__codelineno-21-19">19</a></span>
<span class="normal"><a href="#__codelineno-21-20">20</a></span>
<span class="normal"><a href="#__codelineno-21-21">21</a></span>
<span class="normal"><a href="#__codelineno-21-22">22</a></span>
<span class="normal"><a href="#__codelineno-21-23">23</a></span>
<span class="normal"><a href="#__codelineno-21-24">24</a></span>
<span class="normal"><a href="#__codelineno-21-25">25</a></span>
<span class="normal"><a href="#__codelineno-21-26">26</a></span>
<span class="normal"><a href="#__codelineno-21-27">27</a></span>
<span class="normal"><a href="#__codelineno-21-28">28</a></span>
<span class="normal"><a href="#__codelineno-21-29">29</a></span>
<span class="normal"><a href="#__codelineno-21-30">30</a></span>
<span class="normal"><a href="#__codelineno-21-31">31</a></span>
<span class="normal"><a href="#__codelineno-21-32">32</a></span>
<span class="normal"><a href="#__codelineno-21-33">33</a></span>
<span class="normal"><a href="#__codelineno-21-34">34</a></span>
<span class="normal"><a href="#__codelineno-21-35">35</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">F_score</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-21-3"><a id="__codelineno-21-3" name="__codelineno-21-3"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model has not been fitted yet.&quot;</span><span class="p">)</span>
</span><span id="__span-21-4"><a id="__codelineno-21-4" name="__codelineno-21-4"></a>
</span><span id="__span-21-5"><a id="__codelineno-21-5" name="__codelineno-21-5"></a>    <span class="c1"># Compute residuals using stored training data</span>
</span><span id="__span-21-6"><a id="__codelineno-21-6" name="__codelineno-21-6"></a>    <span class="n">residuals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_residuals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
</span><span id="__span-21-7"><a id="__codelineno-21-7" name="__codelineno-21-7"></a>
</span><span id="__span-21-8"><a id="__codelineno-21-8" name="__codelineno-21-8"></a>    <span class="c1"># Number of observations and number of estimated parameters</span>
</span><span id="__span-21-9"><a id="__codelineno-21-9" name="__codelineno-21-9"></a>    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span>
</span><span id="__span-21-10"><a id="__codelineno-21-10" name="__codelineno-21-10"></a>    <span class="n">p</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="__span-21-11"><a id="__codelineno-21-11" name="__codelineno-21-11"></a>
</span><span id="__span-21-12"><a id="__codelineno-21-12" name="__codelineno-21-12"></a>    <span class="c1"># Residual Sum of Squares (RSS) — unexplained variation</span>
</span><span id="__span-21-13"><a id="__codelineno-21-13" name="__codelineno-21-13"></a>    <span class="n">RSS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">residuals</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="__span-21-14"><a id="__codelineno-21-14" name="__codelineno-21-14"></a>
</span><span id="__span-21-15"><a id="__codelineno-21-15" name="__codelineno-21-15"></a>    <span class="c1"># Total Sum of Squares (TSS) — total variation in y</span>
</span><span id="__span-21-16"><a id="__codelineno-21-16" name="__codelineno-21-16"></a>    <span class="n">TSS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="__span-21-17"><a id="__codelineno-21-17" name="__codelineno-21-17"></a>
</span><span id="__span-21-18"><a id="__codelineno-21-18" name="__codelineno-21-18"></a>    <span class="c1"># Degrees of freedom</span>
</span><span id="__span-21-19"><a id="__codelineno-21-19" name="__codelineno-21-19"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_bias</span><span class="p">:</span>
</span><span id="__span-21-20"><a id="__codelineno-21-20" name="__codelineno-21-20"></a>        <span class="n">df1</span> <span class="o">=</span> <span class="n">p</span> <span class="o">-</span> <span class="mi">1</span>            <span class="c1"># Numerator degrees of freedom (model)</span>
</span><span id="__span-21-21"><a id="__codelineno-21-21" name="__codelineno-21-21"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-21-22"><a id="__codelineno-21-22" name="__codelineno-21-22"></a>        <span class="n">df1</span> <span class="o">=</span> <span class="n">p</span>
</span><span id="__span-21-23"><a id="__codelineno-21-23" name="__codelineno-21-23"></a>    <span class="n">df2</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="n">p</span>            <span class="c1"># Denominator degrees of freedom (residuals)</span>
</span><span id="__span-21-24"><a id="__codelineno-21-24" name="__codelineno-21-24"></a>
</span><span id="__span-21-25"><a id="__codelineno-21-25" name="__codelineno-21-25"></a>    <span class="c1"># Mean Square Regression and Mean Square Error</span>
</span><span id="__span-21-26"><a id="__codelineno-21-26" name="__codelineno-21-26"></a>    <span class="n">MSR</span> <span class="o">=</span> <span class="p">(</span><span class="n">TSS</span> <span class="o">-</span> <span class="n">RSS</span><span class="p">)</span> <span class="o">/</span> <span class="n">df1</span>  <span class="c1"># Explained variance per parameter</span>
</span><span id="__span-21-27"><a id="__codelineno-21-27" name="__codelineno-21-27"></a>    <span class="n">MSE</span> <span class="o">=</span> <span class="n">RSS</span> <span class="o">/</span> <span class="n">df2</span>          <span class="c1"># Unexplained variance per residual degree of freedom</span>
</span><span id="__span-21-28"><a id="__codelineno-21-28" name="__codelineno-21-28"></a>
</span><span id="__span-21-29"><a id="__codelineno-21-29" name="__codelineno-21-29"></a>    <span class="c1"># F-statistic: ratio of explained to unexplained variance</span>
</span><span id="__span-21-30"><a id="__codelineno-21-30" name="__codelineno-21-30"></a>    <span class="n">F_stat</span> <span class="o">=</span> <span class="n">MSR</span> <span class="o">/</span> <span class="n">MSE</span>
</span><span id="__span-21-31"><a id="__codelineno-21-31" name="__codelineno-21-31"></a>
</span><span id="__span-21-32"><a id="__codelineno-21-32" name="__codelineno-21-32"></a>    <span class="c1"># p-value from the F-distribution (right-tailed test)</span>
</span><span id="__span-21-33"><a id="__codelineno-21-33" name="__codelineno-21-33"></a>    <span class="n">p_value</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">F_stat</span><span class="p">,</span> <span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">)</span>
</span><span id="__span-21-34"><a id="__codelineno-21-34" name="__codelineno-21-34"></a>
</span><span id="__span-21-35"><a id="__codelineno-21-35" name="__codelineno-21-35"></a>    <span class="k">return</span> <span class="n">F_stat</span><span class="p">,</span> <span class="n">p_value</span>
</span></code></pre></div></td></tr></table></div>
<h5 id="standard-errors-of-coefficients">Standard Errors of Coefficients<a class="headerlink" href="#standard-errors-of-coefficients" title="Permanent link">&para;</a></h5>
<p>The <strong>standard error</strong> of each regression coefficient measures the variability of its estimate across hypothetical repeated samples.
It comes from the diagonal entries of the <strong>variance–covariance matrix</strong> of <span class="arithmatex">\( \boldsymbol{\beta} \)</span>.</p>
<p>The method works as follows:</p>
<ul>
<li>
<p><strong>Get residuals from stored training data</strong>:
   We call the internal <code>_residuals(self.X, self.y)</code> to compute
   $$
   \mathbf{r} = \mathbf{y} - \hat{\mathbf{y}}.
   $$</p>
</li>
<li>
<p><strong>Compute <span class="arithmatex">\((X^\top X)^{-1}\)</span></strong>:
   This matrix appears in the closed-form OLS solution and is needed to propagate uncertainty into the coefficient estimates.</p>
</li>
<li>
<p><strong>Estimate the variance of the residuals</strong>:
   Using
   $$
   \hat{\sigma}^2 = \frac{\text{RSS}}{n - p}
   $$
   where:</p>
<ul>
<li><span class="arithmatex">\(\text{RSS} = \sum_i r_i^2\)</span> is the residual sum of squares,</li>
<li><span class="arithmatex">\(n\)</span> is the number of observations,</li>
<li><span class="arithmatex">\(p\)</span> is the number of estimated parameters (including the intercept).</li>
</ul>
</li>
<li>
<p><strong>Form the variance–covariance matrix of <span class="arithmatex">\(\boldsymbol{\beta}\)</span></strong>:
   $$
   \text{Var}(\boldsymbol{\beta}) = \hat{\sigma}^2 \, (X^\top X)^{-1}.
   $$</p>
</li>
<li>
<p><strong>Extract standard errors</strong>:
   Take the square root of each diagonal element to get
   $$
   \text{SE}(\beta_j) = \sqrt{ \text{Var}(\beta_j) }.
   $$</p>
</li>
</ul>
<p>These standard errors are crucial for computing <strong>t-statistics</strong> and <strong>p-values</strong> when testing the significance of each coefficient.</p>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-22-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-22-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-22-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-22-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-22-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-22-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-22-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-22-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-22-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-22-10">10</a></span>
<span class="normal"><a href="#__codelineno-22-11">11</a></span>
<span class="normal"><a href="#__codelineno-22-12">12</a></span>
<span class="normal"><a href="#__codelineno-22-13">13</a></span>
<span class="normal"><a href="#__codelineno-22-14">14</a></span>
<span class="normal"><a href="#__codelineno-22-15">15</a></span>
<span class="normal"><a href="#__codelineno-22-16">16</a></span>
<span class="normal"><a href="#__codelineno-22-17">17</a></span>
<span class="normal"><a href="#__codelineno-22-18">18</a></span>
<span class="normal"><a href="#__codelineno-22-19">19</a></span>
<span class="normal"><a href="#__codelineno-22-20">20</a></span>
<span class="normal"><a href="#__codelineno-22-21">21</a></span>
<span class="normal"><a href="#__codelineno-22-22">22</a></span>
<span class="normal"><a href="#__codelineno-22-23">23</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">coefficients_SE</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-22-3"><a id="__codelineno-22-3" name="__codelineno-22-3"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model has not been fitted yet.&quot;</span><span class="p">)</span>
</span><span id="__span-22-4"><a id="__codelineno-22-4" name="__codelineno-22-4"></a>
</span><span id="__span-22-5"><a id="__codelineno-22-5" name="__codelineno-22-5"></a>    <span class="c1"># Compute residuals from stored data</span>
</span><span id="__span-22-6"><a id="__codelineno-22-6" name="__codelineno-22-6"></a>    <span class="n">residuals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_residuals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
</span><span id="__span-22-7"><a id="__codelineno-22-7" name="__codelineno-22-7"></a>
</span><span id="__span-22-8"><a id="__codelineno-22-8" name="__codelineno-22-8"></a>    <span class="c1"># Compute (X^T X)^(-1)</span>
</span><span id="__span-22-9"><a id="__codelineno-22-9" name="__codelineno-22-9"></a>    <span class="n">XtX_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
</span><span id="__span-22-10"><a id="__codelineno-22-10" name="__codelineno-22-10"></a>
</span><span id="__span-22-11"><a id="__codelineno-22-11" name="__codelineno-22-11"></a>    <span class="c1"># Compute estimated variance of errors</span>
</span><span id="__span-22-12"><a id="__codelineno-22-12" name="__codelineno-22-12"></a>    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span>
</span><span id="__span-22-13"><a id="__codelineno-22-13" name="__codelineno-22-13"></a>    <span class="n">p</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="__span-22-14"><a id="__codelineno-22-14" name="__codelineno-22-14"></a>    <span class="n">RSS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">residuals</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="__span-22-15"><a id="__codelineno-22-15" name="__codelineno-22-15"></a>    <span class="n">sigma_squared</span> <span class="o">=</span> <span class="n">RSS</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>
</span><span id="__span-22-16"><a id="__codelineno-22-16" name="__codelineno-22-16"></a>
</span><span id="__span-22-17"><a id="__codelineno-22-17" name="__codelineno-22-17"></a>    <span class="c1"># Compute variance-covariance matrix of beta</span>
</span><span id="__span-22-18"><a id="__codelineno-22-18" name="__codelineno-22-18"></a>    <span class="n">var_beta</span> <span class="o">=</span> <span class="n">sigma_squared</span> <span class="o">*</span> <span class="n">XtX_inv</span>
</span><span id="__span-22-19"><a id="__codelineno-22-19" name="__codelineno-22-19"></a>
</span><span id="__span-22-20"><a id="__codelineno-22-20" name="__codelineno-22-20"></a>    <span class="c1"># Standard errors are the square roots of the diagonal entries</span>
</span><span id="__span-22-21"><a id="__codelineno-22-21" name="__codelineno-22-21"></a>    <span class="n">coeff_RSE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">var_beta</span><span class="p">))</span>
</span><span id="__span-22-22"><a id="__codelineno-22-22" name="__codelineno-22-22"></a>
</span><span id="__span-22-23"><a id="__codelineno-22-23" name="__codelineno-22-23"></a>    <span class="k">return</span> <span class="n">coeff_RSE</span>
</span></code></pre></div></td></tr></table></div>
<h5 id="t-stats-and-p-values-for-coefficients">t-stats and p-values for Coefficients<a class="headerlink" href="#t-stats-and-p-values-for-coefficients" title="Permanent link">&para;</a></h5>
<p>Once we have the <strong>standard errors</strong> of the regression coefficients, we can test whether each coefficient is statistically different from zero.</p>
<ul>
<li>
<p><strong>Compute t-statistics</strong>
   For each coefficient <span class="arithmatex">\( \beta_j \)</span>, the <strong>t-statistic</strong> is computed as:
   $$
   t_j = \frac{\beta_j}{\mathrm{SE}(\beta_j)}
   $$
   This measures how many standard errors the coefficient is away from zero.</p>
</li>
<li>
<p><strong>Determine degrees of freedom</strong>
   We use:
   $$
   \text{df} = n - p
   $$
   where:</p>
<ul>
<li><span class="arithmatex">\(n\)</span> is the number of observations,</li>
<li><span class="arithmatex">\(p\)</span> is the number of parameters estimated (including the intercept).</li>
</ul>
</li>
<li>
<p><strong>Compute two-tailed p-values</strong>
   Under the null hypothesis <span class="arithmatex">\(H_0 : \beta_j = 0\)</span>, the t-statistic follows a <strong>Student’s t-distribution</strong> with <span class="arithmatex">\(n - p\)</span> degrees of freedom.
   The two-tailed p-value is:
   $$
   p_j = 2 \left( 1 - F_t\left( \left| t_j \right| \right) \right)
   $$
   where <span class="arithmatex">\(F_t\)</span> is the cumulative distribution function (CDF) of the t-distribution.</p>
</li>
</ul>
<p>These p-values indicate the probability of observing such extreme <span class="arithmatex">\(t\)</span>-statistics if the true coefficient were zero.
Small p-values (commonly below 0.05) suggest that the coefficient is statistically significant.</p>
<div class="language-python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-23-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-23-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-23-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-23-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-23-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-23-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-23-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-23-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-23-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-23-10">10</a></span>
<span class="normal"><a href="#__codelineno-23-11">11</a></span>
<span class="normal"><a href="#__codelineno-23-12">12</a></span>
<span class="normal"><a href="#__codelineno-23-13">13</a></span>
<span class="normal"><a href="#__codelineno-23-14">14</a></span>
<span class="normal"><a href="#__codelineno-23-15">15</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">coefficients_p_values</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]]:</span>
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-23-3"><a id="__codelineno-23-3" name="__codelineno-23-3"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model has not been fitted yet.&quot;</span><span class="p">)</span>
</span><span id="__span-23-4"><a id="__codelineno-23-4" name="__codelineno-23-4"></a>
</span><span id="__span-23-5"><a id="__codelineno-23-5" name="__codelineno-23-5"></a>    <span class="c1"># Compute t-statistics: each beta divided by its standard error</span>
</span><span id="__span-23-6"><a id="__codelineno-23-6" name="__codelineno-23-6"></a>    <span class="n">t_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">coefficients_SE</span><span class="p">()</span>
</span><span id="__span-23-7"><a id="__codelineno-23-7" name="__codelineno-23-7"></a>
</span><span id="__span-23-8"><a id="__codelineno-23-8" name="__codelineno-23-8"></a>    <span class="c1"># Number of observations and number of parameters</span>
</span><span id="__span-23-9"><a id="__codelineno-23-9" name="__codelineno-23-9"></a>    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
</span><span id="__span-23-10"><a id="__codelineno-23-10" name="__codelineno-23-10"></a>    <span class="n">p</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
</span><span id="__span-23-11"><a id="__codelineno-23-11" name="__codelineno-23-11"></a>
</span><span id="__span-23-12"><a id="__codelineno-23-12" name="__codelineno-23-12"></a>    <span class="c1"># Compute two-tailed p-values using the t-distribution CDF</span>
</span><span id="__span-23-13"><a id="__codelineno-23-13" name="__codelineno-23-13"></a>    <span class="n">p_values</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_values</span><span class="p">),</span> <span class="n">df</span><span class="o">=</span><span class="n">n</span> <span class="o">-</span> <span class="n">p</span><span class="p">))</span>
</span><span id="__span-23-14"><a id="__codelineno-23-14" name="__codelineno-23-14"></a>
</span><span id="__span-23-15"><a id="__codelineno-23-15" name="__codelineno-23-15"></a>    <span class="k">return</span> <span class="n">t_values</span><span class="p">,</span> <span class="n">p_values</span>
</span></code></pre></div></td></tr></table></div>
<h5 id="summary-method">Summary method<a class="headerlink" href="#summary-method" title="Permanent link">&para;</a></h5>
<p>Together, all of these statistics can be used to generate our own summary function. See <code>summary(self)</code> in <code>lin_reg.py</code>.</p>
<hr>
<hr>

<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>Testing is beyond the scope of this tutorial, but it is an essential skill in software development. Automated tests help ensure that your code produces the expected results, prevent regressions when you make changes, and improve confidence in the correctness of your program.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p>In general, I will reduce the docstrings for presentation here. You can gain additional context by looking through the docstrings in <code>lin_reg.py</code>.&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": ".", "features": ["content.code.annotate", "content.code.copy"], "search": "assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="assets/javascripts/bundle.50899def.min.js"></script>
      
        <script src="javascripts/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>